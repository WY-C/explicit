import itertools, os, json, re
from collections import defaultdict
import numpy as np
import pkg_resources
import sys 
import copy 
from .modules import Module
from overcooked_ai_py.mdp.actions import Action, Direction
from overcooked_ai_py.planning.search import find_path 
from overcooked_ai_py.planning.search import get_intersect_counter 
from overcooked_ai_py.planning.search import query_counter_states 
import time
import threading  # [NEW] ë©€í‹°ìŠ¤ë ˆë”©ì„ ìœ„í•œ ëª¨ë“ˆ
import random # ê³ ë¯¼ì¤‘ì— random ì•¡ì…˜
from overcooked_ai_py.mdp.overcooked_mdp import OvercookedState
cwd = os.getcwd()
openai_key_file = os.path.join(cwd, "openai_key.txt")
PROMPT_DIR = os.path.join(cwd, "prompts")

NAME_TO_ACTION = {
    "NORTH": Direction.NORTH,
    "SOUTH": Direction.SOUTH,
    "EAST": Direction.EAST,
    "WEST": Direction.WEST,
    "INTERACT": Action.INTERACT,
    "STAY": Action.STAY
}


class ProAgent(object):
    """
    This agent uses GPT-3.5 to generate actions.
    """
    def __init__(self, model="Qwen/Qwen2-VL-7B-Instruct-AWQ"):
        self.agent_index = None
        self.model = model

        self.openai_api_keys = []
        self.load_openai_keys()
        self.key_rotation = True
        # [NEW] ë¼ì„(Stuck) ê°ì§€ìš© ë³€ìˆ˜
        self.stuck_steps = 0
        self.last_pos_for_stuck = None

    def load_openai_keys(self):
        with open(openai_key_file, "r") as f:
            context = f.read()
        self.openai_api_keys = context.split('\n')

    def openai_api_key(self):
        if self.key_rotation:
            self.update_openai_key()
        return self.openai_api_keys[0]

    def update_openai_key(self):
        self.openai_api_keys.append(self.openai_api_keys.pop(0))

    def set_agent_index(self, agent_index):
        raise NotImplementedError

    def action(self, state):
        raise NotImplementedError

    def reset(self):
        raise NotImplementedError


class ProMediumLevelAgent(ProAgent):
    """
    This agent default to use GPT-3.5 to generate medium level actions.
    Now supports Asynchronous Execution (Non-blocking).
    """
    def __init__(
            self,
            mlam,
            layout,
            model = "Qwen/Qwen3-VL-8B-Instruct",
            prompt_level='l2-ap', 
            belief_revision=False,
            retrival_method="recent_k",
            K=3,
            auto_unstuck=True,
            controller_mode='new', 
            debug_mode='N', 
            agent_index=None,
            outdir = None,

    ):
        super().__init__(model=model)
        self.trace = True 
        self.debug_mode = 'Y' 
        self.controller_mode = controller_mode 
        self.mlam = mlam
        self.layout = layout
        self.mdp = self.mlam.mdp
        
        self.out_dir = outdir 
        self.agent_index = agent_index

        self.prompt_level = prompt_level
        self.belief_revision = belief_revision

        self.retrival_method = retrival_method
        self.K = K
        
        self.prev_state = None
        self.auto_unstuck = auto_unstuck

        self.current_ml_action = None
        self.current_ml_action_steps = 0
        self.time_to_wait = 0
        self.possible_motion_goals = None
        self.pot_id_to_pos = []
        self.global_id_mapping = {
            "onion_dispenser": [],
            "dish_dispenser": [],
            "tomato_dispenser": [],
            "serving": [],
            "pot": []
        }
        self.cached_terrain_matrix = {
            'matrix': copy.deepcopy(self.mlam.mdp.terrain_mtx), 
            'height': len(self.mlam.mdp.terrain_mtx),
            'width': len(self.mlam.mdp.terrain_mtx[0])
        }
        self.action_regex = re.compile(r'\((\s*\d+\s*)\)')
        self.overcooked_version = pkg_resources.get_distribution("overcooked_ai").version

        # [ì´ˆê¸°í™”]
        self.layout_prompt = ""
        self.partner_move_history = []

        # [NEW] ë¹„ë™ê¸° ì²˜ë¦¬ ë° íƒ€ì„ì•„ì›ƒì„ ìœ„í•œ ë³€ìˆ˜
        self.is_thinking = False       
        self.think_thread = None       
        self.next_ml_action = None     
        self.lock = threading.Lock()   
        self.prev_partner_move = None
        self.current_thought = ""
        
        # [NEW] íƒ€ì„ì•„ì›ƒ/ì¬ìš”ì²­ ê´€ë¦¬ ë³€ìˆ˜
        self.thinking_start_time = 0.0  # ìƒê° ì‹œì‘ ì‹œê°„
        self.thinking_request_id = 0    # ìš”ì²­ ê³ ìœ  ID (ì˜¤ë˜ëœ ìš”ì²­ ë¬´ì‹œìš©)
        self.TIMEOUT_SECONDS = 4.0      # 3ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •


    def set_mdp(self, mdp):
        self.mdp = mdp

    def create_gptmodule(self, module_name, file_type='txt', retrival_method='recent_k', K=10):
        print(f"\n--->Initializing GPT {module_name}<---\n")    

        # prompt_file = os.path.join(PROMPT_DIR, self.model, module_name, self.layout+f'_{self.agent_index}.'+file_type)

        if "gpt" in self.model or "text-davinci" in self.model or "Qwen" in self.model:
            model_name = "gpt"
        elif "claude" in self.model:
            model_name = "claude"
    
        if module_name == "planner":
            prompt_file = os.path.join(PROMPT_DIR, model_name, module_name, self.prompt_level.strip(), f'{self.layout}_{self.agent_index}.{file_type}')
        elif module_name == "explainer":
            prompt_file = os.path.join(PROMPT_DIR, model_name, module_name, f'player{self.agent_index}.{file_type}')
        else:
            raise Exception(f"Module {module_name} not supported.")
        
        with open(prompt_file, "r") as f:
            if file_type == 'json':
                messages = json.load(f)
            elif file_type == 'txt':
                messages = [{"role": "system", "content": f.read()}]
            else:
                print("Unsupported file format.")
        
        return Module(messages, self.model, retrival_method, K)

    def reset(self):
        self.planner.reset()
        self.explainer.reset()
        self.prev_state = None
        self.current_ml_action = None
        self.current_ml_action_steps = 0
        self.time_to_wait = 0
        self.possible_motion_goals = None
        self.current_timestep = 0
        self.teammate_ml_actions_dict = {}
        self.teammate_intentions_dict = {}
        self.stuck_steps = 0
        self.last_pos_for_stuck = None
        
        # [NEW] ë¹„ë™ê¸° ìƒíƒœ ì´ˆê¸°í™”
        with self.lock:
            self.is_thinking = False
            self.next_ml_action = None

    def set_agent_index(self, agent_index):
        self.agent_index = agent_index
        self.planner = self.create_gptmodule("planner", retrival_method=self.retrival_method, K=self.K)
        self.explainer = self.create_gptmodule("explainer", retrival_method='recent_k', K=self.K)

        print(self.planner.instruction_head_list[0]['content'])
      
    def generate_layout_prompt(self, my_pos, other_pos):
        """
        [ìµœì í™” V3] ì„œë¹™ ì¹´ìš´í„°(Serve) ì¶”ê°€ ë° í¬ë§· í†µì¼
        ì¶œë ¥ ì˜ˆì‹œ: <Serve 0> [P0:5, P1:2]
        """
        # 1. ë§¤í•‘ ì´ˆê¸°í™”
        self.global_id_mapping = {
            "onion_dispenser": [], "dish_dispenser": [], "tomato_dispenser": [], "serving": [], "pot": []
        }
        self.pot_id_to_pos = [] 

        # 2. ì´ë¦„ ë§¤í•‘ (Serve ì¶”ê°€ë¨)
        name_map = {
            "onion_dispenser": "OnionD",    # Dispenser
            "dish_dispenser": "DishD",      # Dispenser
            "serving": "Serve",             # [ì¤‘ìš”] Serving Location ì¶”ê°€
            "pot": "Pot"
        }

        layout_prompt = "Layout: "
        
        # 3. ê°ì²´ ìˆœíšŒ ë° ê±°ë¦¬ ê³„ì‚°
        for key, readable_name in name_map.items():
            # MDPì—ì„œ ìœ„ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (get_serving_locations ë“±)
            locations = getattr(self.mdp, f"get_{key}_locations")()
            self.global_id_mapping[key] = locations
            
            if not locations:
                continue
                
            items_str_list = []
            for i, pos in enumerate(locations):
                # --- ê±°ë¦¬ ê³„ì‚° ë¡œì§ (Player IDì— ë§ì¶° í• ë‹¹) ---
                # self.agent_indexê°€ 0ì´ë©´ my_posê°€ P0, other_posê°€ P1
                if self.agent_index == 0:
                    dist_p0 = abs(pos[0] - my_pos[0]) + abs(pos[1] - my_pos[1])
                    dist_p1 = abs(pos[0] - other_pos[0]) + abs(pos[1] - other_pos[1])
                else: # self.agent_indexê°€ 1ì´ë©´ my_posê°€ P1, other_posê°€ P0
                    dist_p1 = abs(pos[0] - my_pos[0]) + abs(pos[1] - my_pos[1])
                    dist_p0 = abs(pos[0] - other_pos[0]) + abs(pos[1] - other_pos[1])

                # [ìµœì¢… í¬ë§·] ì¢Œí‘œ ì œê±°, Serve í¬í•¨, ë‹¨ì¶•ëœ ê±°ë¦¬ í‘œê¸°
                # ì˜ˆ: <Serve 0> [P0:5, P1:2]
                items_str_list.append(f"<{readable_name} {i}> [P0:{dist_p0}, P1:{dist_p1}]")
                
                if key == "pot":
                    self.pot_id_to_pos.append(pos)
            
            # í•­ëª©ë³„ë¡œ ë¬¶ì–´ì„œ ì¶”ê°€ (ì˜ˆ: Serve: <Serve 0> [...], <Serve 1> [...]; )
            layout_prompt += f"{', '.join(items_str_list)}; "

        return layout_prompt.strip() + "\n"
    def generate_state_prompt(self, state):
        ego = state.players[self.agent_index]
        teammate = state.players[1 - self.agent_index]
        self.layout_prompt = self.generate_layout_prompt(ego.position, teammate.position)
            

        history_prompt = ""
        #self.partner_move_history = []

        curr_partner_pos = teammate.position
        partner_idx = 1 - self.agent_index
        
        # [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ IDë¥¼ íŒŒíŠ¸ë„ˆ IDë¡œ ë³€ê²½
        history_prompt += f"\n<Player {partner_idx}> History: "

        # ê²½ë¡œ ë¬¸ìì—´ ìƒì„± (ì˜ˆ: (1,1) -> (1,2) -> (2,2) -> (2,3))
        if not self.partner_move_history:
            # ì²« ì‹œì‘ì¸ ê²½ìš°
            move_str = f"Start -> {curr_partner_pos}"
            is_blocked = False
        else:
            # ê³¼ê±° ê¸°ë¡ë“¤ì„ í™”ì‚´í‘œë¡œ ì—°ê²°
            past_moves_str = " -> ".join([str(pos) for pos in self.partner_move_history])
            move_str = f"{past_moves_str} -> {curr_partner_pos}"
        

        history_prompt += f"Moved: {move_str}"
        
        self.partner_move_history.append(curr_partner_pos)
        if len(self.partner_move_history) >= 5:
            self.partner_move_history.pop(0)
            


        # =========================================================
        # 3. ê¸°ì¡´ ì •ë³´ë“¤ (ì‹œê°„, í”Œë ˆì´ì–´ ìƒíƒœ)
        # =========================================================
        time_prompt = f"Scene {state.timestep}: "
        
        # Ego(ë‚˜) ìƒíƒœ ì„¤ëª…
        ego_object = ego.held_object.name if ego.held_object else "nothing"
        ego_state_prompt = f"<Player {self.agent_index}> holds "
        if ego_object == 'soup':
            ego_state_prompt += f"a dish with {ego_object} and needs to deliver soup. "
        elif ego_object == 'nothing':
            ego_state_prompt += f"{ego_object}. "
        else:
            ego_state_prompt += f"one {ego_object}. "
        ego_state_prompt += f" at {ego.position}. "
        
        # Teammate(ë™ë£Œ) ìƒíƒœ ì„¤ëª…
        teammate_object = teammate.held_object.name if teammate.held_object else "nothing"
        teammate_state_prompt = f"<Player {1-self.agent_index}> holds "
        if teammate_object == 'soup':
            teammate_state_prompt += f"a dish with {teammate_object}. "
        elif teammate_object == "nothing":
            teammate_state_prompt += f"{teammate_object}. "
        else:
            teammate_state_prompt += f"one {teammate_object}. "
        teammate_state_prompt += f" at {teammate.position}. "

        # =========================================================
        # 4. ì£¼ë°© ëƒ„ë¹„ ìƒíƒœ (Kitchen State)
        # =========================================================
        kitchen_state_prompt = "Kitchen states: "
        prompt_dict = {
            "empty": "<Pot {id}> is empty; ",
            "cooking": "<Pot {id}> starts cooking, the soup will be ready after {t} timesteps; ",
            "ready": "<Pot {id}> has already cooked the soup; ",
            "1_items": "<Pot {id}> has 1 onion; ",
            "2_items": "<Pot {id}> has 2 onions; ",
            "3_items": "<Pot {id}> has 3 onions and is full; "
        }

        pot_states_dict = self.mdp.get_pot_states(state)   
        # ë²„ì „ë³„ ëƒ„ë¹„ ìƒíƒœ ì²˜ë¦¬ ë¡œì§
        if self.overcooked_version== '1.1.0':
            for key in pot_states_dict.keys():
                if key == "cooking":
                    for pos in pot_states_dict[key]:
                        pot_id = self.pot_id_to_pos.index(pos)
                        soup_object = state.get_object(pos)
                        kitchen_state_prompt += prompt_dict[key].format(id=pot_id, t=soup_object.cook_time_remaining)
                else:
                    for pos in pot_states_dict[key]:
                        pot_id = self.pot_id_to_pos.index(pos)
                        kitchen_state_prompt += prompt_dict[key].format(id=pot_id) 
        
        elif self.overcooked_version== '0.0.1':
            for key in pot_states_dict.keys():
                if key == "empty":
                    for pos in pot_states_dict[key]: 
                        pot_id = self.pot_id_to_pos.index(pos)
                        kitchen_state_prompt += prompt_dict[key].format(id=pot_id)     
                else: 
                    for soup_key in pot_states_dict[key].keys():
                        for pos in pot_states_dict[key][soup_key]:
                            pot_id = self.pot_id_to_pos.index(pos)
                            soup_object = state.get_object(pos)
                            soup_type, num_items, cook_time = soup_object.state
                            if soup_key == "cooking":
                                kitchen_state_prompt += prompt_dict[soup_key].format(id=pot_id, t=self.mdp.soup_cooking_time-cook_time)
                            elif soup_key == "partially_full":
                                pass
                            else:
                                kitchen_state_prompt += prompt_dict[soup_key].format(id=pot_id)

        # Forced Coordination ë§µ íŠ¹ìˆ˜ ì²˜ë¦¬
        if self.layout == 'forced_coordination': 
            from utils import get_intersect_counter, query_counter_states
            intersect_counters = get_intersect_counter(
                                state.players_pos_and_or[self.agent_index], 
                                state.players_pos_and_or[1 - self.agent_index], 
                                self.mdp, 
                                self.mlam
                            )
            counter_states = query_counter_states(self.mdp, state)  
            
            kitchen_state_prompt += '{} counters can be visited by <Player {}>. Their states are as follows: '.format(len(intersect_counters), self.agent_index)
            count_states = {}  
            for i in intersect_counters:  
                obj_i = 'nothing' 
                if counter_states[i] != ' ': 
                    obj_i = counter_states[i]                
                if obj_i in count_states:  
                    count_states[obj_i] += 1
                else: 
                    count_states[obj_i]  = 1 
            total_obj = ['onion', 'dish']
            for i in count_states:   
                if i == 'nothing': 
                    continue 
                kitchen_state_prompt += f'{count_states[i]} counters have {i}. '   
            for i in total_obj: 
                if i not in count_states:        
                    kitchen_state_prompt += f'No counters have {i}. ' 

            teammate_state_prompt = "" # ì´ ë§µì—ì„œëŠ” ë™ë£Œ ì •ë³´ ìˆ¨ê¹€

        # =========================================================
        # 5. [í•µì‹¬ ìˆ˜ì •] ìµœì¢… ì¡°í•© ë°©ì‹ ë³€ê²½
        # =========================================================
        # ê° íŒŒíŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê³ , .strip()ìœ¼ë¡œ ì•ë’¤ ê³µë°±/ê°œí–‰ì„ ì œê±°í•œ ë’¤
        # '\n'ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì¤‘ë³µ ì¤„ë°”ê¿ˆì„ ë°©ì§€í•˜ê³  ê¹”ë”í•œ í¬ë§·ì„ ë§Œë“­ë‹ˆë‹¤.
        
        # Scene ì„¤ëª…ê³¼ í”Œë ˆì´ì–´ ì •ë³´ëŠ” ë³´í†µ í•œ ì¤„ì´ë‚˜ ë¶™ì–´ìˆëŠ” ë¬¸ë‹¨ìœ¼ë¡œ ì·¨ê¸‰í•˜ë¯€ë¡œ í•©ì¹©ë‹ˆë‹¤.
        scene_block = time_prompt + ego_state_prompt + teammate_state_prompt

        # print("LAYOUT PROMPT:", self.layout_prompt)
        # print("SCENE BLOCK:", scene_block)
        # print("HISTORY PROMPT:", history_prompt)
        # print("KITCHEN STATE PROMPT:", kitchen_state_prompt)

        parts = [
            self.layout_prompt.strip(),  # Layout
            scene_block.strip(),         # Scene + Players
            history_prompt.strip(),      # History
            kitchen_state_prompt.strip() # Kitchen
        ]
        
        # ë‚´ìš©ì´ ìˆëŠ” íŒŒíŠ¸ë§Œ \nìœ¼ë¡œ ì—°ê²°
        final_prompt = "\n".join([p for p in parts if p])
        
        # ë””ë²„ê¹…ìš© ì¶œë ¥
        print("PROMPT:", final_prompt)
        return final_prompt
    
    
    def generate_belief_prompt(self):
        ego_id = self.agent_index
        intention_prompt = f"All <Player {ego_id}> infered intentions about <Player {1-ego_id}>: {self.teammate_intentions_dict}.\n"
        real_behavior_prompt = f"<Player {1-ego_id}> real behaviors: {self.teammate_ml_actions_dict}.\n"
        belief_prompt = intention_prompt + real_behavior_prompt
        return belief_prompt
    
    ##################
    '''
    The followings are the Planner part (THREADED)
    '''
    ##################
    def _thinking_process(self, state_dict, request_id):
        """
        [Modified] request_idë¥¼ ì¸ìë¡œ ë°›ì•„ì„œ, ìµœì‹  ìš”ì²­ì¼ ë•Œë§Œ ê²°ê³¼ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.
        """
        try:
            current_state = OvercookedState.from_dict(state_dict)
            
            # LLM í˜¸ì¶œ (ì‹œê°„ì´ ê±¸ë¦¼)
            plan = self.generate_ml_action(current_state)

            with self.lock:
                # [ì¤‘ìš”] í˜„ì¬ ì²˜ë¦¬í•œ ê²°ê³¼ê°€ ìµœì‹  ìš”ì²­(request_id)ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                # ë§Œì•½ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì´ë¯¸ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ request_idë¥¼ ì˜¬ë ¸ë‹¤ë©´, 
                # ì´ ê²°ê³¼ëŠ” ë²„ë ¤ì§‘ë‹ˆë‹¤ (ëŠ¦ê²Œ ë„ì°©í•œ íŒ¨í‚· ë¬´ì‹œ).
                if self.thinking_request_id == request_id:
                    self.next_ml_action = plan
                    self.is_thinking = False
                # else: 
                #     print(f" [Thread] Discarded old result (Req:{request_id} != Curr:{self.thinking_request_id})")

        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ìƒíƒœ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ ì²´í¬
            import traceback
            traceback.print_exc()
            with self.lock:
                if self.thinking_request_id == request_id:
                    self.is_thinking = False

    def _correction_process(self, state_snapshot):
        """
        [NEW] Thread Function: Correction (Failure Recovery)
        ê²€ì¦ ì‹¤íŒ¨ ì‹œ Explainer í˜¸ì¶œ í›„ í–‰ë™ ì¬ìƒì„±
        """
        try:
            print(f"\n[Agent] Validation Failed! Asking Explainer & Re-planning...")
            
            # # 1. ì‹¤íŒ¨ í”¼ë“œë°± ìƒì„± (Explainer LLM í˜¸ì¶œ - ì‹œê°„ ì†Œìš”)
            # ì‹¤ì‹œê°„ì„±ì„ ìœ„í•´ ìŠ¤í‚µí•˜ê¸°
            self.generate_failure_feedback(state_snapshot)
            
            # 2. í–‰ë™ ì¬ìƒì„± (Planner LLM í˜¸ì¶œ - ì‹œê°„ ì†Œìš”)
            new_action = self.generate_ml_action(state_snapshot)
            
            # ê²°ê³¼ ì €ì¥
            with self.lock:
                self.next_ml_action = new_action
                self.is_thinking = False
                
        except Exception as e:
            print(f"[Error in Correction Thread] {e}")
            with self.lock:
                self.is_thinking = False

    def action(self, state):
        """
        [Modified] 3ìŠ¤í… ì œìë¦¬ ë©ˆì¶¤(Stuck) ê°ì§€ ë¡œì§ ì ìš©
        """
        current_pos = state.players[self.agent_index].position

        # 1. í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ High-Level Action ê´€ë¦¬
        if self.current_ml_action is not None:
            
            # --- [NEW] ì œìë¦¬ ë©ˆì¶¤ ê°ì§€ (ìœ„ì¹˜ê°€ ê·¸ëŒ€ë¡œë©´ ì¹´ìš´íŠ¸ ì¦ê°€) ---
            if self.last_pos_for_stuck == current_pos:
                self.stuck_steps += 1
            else:
                self.stuck_steps = 0  # í•œ ì¹¸ì´ë¼ë„ ì›€ì§ì´ë©´ ì´ˆê¸°í™”
            
            self.last_pos_for_stuck = current_pos

            # ğŸš¨ 3ìŠ¤í… ë™ì•ˆ ì œìë¦¬ì— ë©ˆì¶°ìˆê³ , ì˜ë„í•œ 'wait' í–‰ë™ì´ ì•„ë‹ˆë¼ë©´ ê°•ì œ ì·¨ì†Œ!
            if self.stuck_steps >= 3 and "wait" not in self.current_ml_action:
                print(f"\n[Stuck] ì œìë¦¬ì— 3ìŠ¤í… ì´ìƒ ë§‰í˜€ì„œ '{self.current_ml_action}' ê°•ì œ ì·¨ì†Œ! ë‹¤ì‹œ ìƒê°í•©ë‹ˆë‹¤.")
                self.trace = False
                self.current_ml_action = None
                self.stuck_steps = 0
                with self.lock:
                    self.is_thinking = False
                    
            elif self.check_current_ml_action_done(state):
                self.generate_success_feedback(state)
                self.current_ml_action = None 
                self.stuck_steps = 0 # ì™„ë£Œ ì‹œ ì´ˆê¸°í™”
                
            elif not self.validate_current_ml_action(state):
                self.trace = False
                self.current_ml_action = None
                self.stuck_steps = 0 # ì‹¤íŒ¨ ì‹œ ì´ˆê¸°í™”
                with self.lock:
                    self.is_thinking = False

        # 2. ìƒê°(Thinking) ê´€ë¦¬ ë¡œì§ (íƒ€ì„ì•„ì›ƒ & ì¬ìš”ì²­ í¬í•¨)
        if self.current_ml_action is None:
            with self.lock:
                current_time = time.time()
                
                # (A) ê²°ê³¼ ë„ì°© í™•ì¸ (ì„±ê³µ)
                if self.next_ml_action is not None:
                    self.current_ml_action = self.next_ml_action
                    self.next_ml_action = None
                    self.current_ml_action_steps = 0
                    
                    # ğŸš¨ [ëˆ„ë½ëë˜ ë¶€ë¶„ ì¶”ê°€] wait ì•¡ì…˜ì¼ ê²½ìš° ëŒ€ê¸° ì‹œê°„ì„ íŒŒì‹±í•´ì„œ ì„¤ì •í•´ì¤ë‹ˆë‹¤.
                    if "wait" in self.current_ml_action:
                        import re
                        nums = re.findall(r'\d+', self.current_ml_action)
                        self.time_to_wait = int(nums[0]) if nums else 1

                    if hasattr(self, 'last_llm_timing'):
                        print(f" >> LLM Timing: {json.dumps(self.last_llm_timing)}")
                
                # (B) [í•µì‹¬] íƒ€ì„ì•„ì›ƒ ì²´í¬ ë° ì¬ìš”ì²­
                # ìƒê° ì¤‘ì¸ë° 3ì´ˆê°€ ì§€ë‚¬ë‹¤ë©´? -> ê¸°ì¡´ ê²ƒ ë²„ë¦¬ê³  ìƒˆë¡œ ìš”ì²­
                elif self.is_thinking and (current_time - self.thinking_start_time > self.TIMEOUT_SECONDS):
                    print(f"\n[Timeout] LLM took > {self.TIMEOUT_SECONDS}s. Retrying with NEW state...")
                    
                    # 1. ID ì¦ê°€ (ì´ì „ ìŠ¤ë ˆë“œì˜ ê²°ê³¼ê°€ ë‚˜ì¤‘ì— ì™€ë„ ë¬´ì‹œë¨)
                    self.thinking_request_id += 1
                    
                    # 2. íƒ€ì´ë¨¸ ë¦¬ì…‹
                    self.thinking_start_time = current_time
                    
                    # 3. ìƒˆ ìŠ¤ë ˆë“œ ì‹œì‘ (í˜„ì¬ì˜ ìµœì‹  state ì‚¬ìš©)
                    safe_data = state.to_dict()
                    req_id = self.thinking_request_id
                    
                    # ì´ì „ ìŠ¤ë ˆë“œëŠ” ê°•ì œ ì¢…ë£Œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëŒë‹¤ê°€ _thinking_processì˜ ID ì²´í¬ì—ì„œ ê±¸ëŸ¬ì§‘ë‹ˆë‹¤.
                    self.think_thread = threading.Thread(target=self._thinking_process, args=(safe_data, req_id))
                    self.think_thread.start()

                # (C) ìƒê°ì´ ì•ˆ ëŒê³  ìˆë‹¤ë©´ -> ìµœì´ˆ ìƒê° ì‹œì‘
                elif not self.is_thinking:
                    self.is_thinking = True
                    self.thinking_start_time = current_time
                    self.thinking_request_id += 1 # ìƒˆ ID ë°œê¸‰
                    
                    safe_data = state.to_dict()
                    req_id = self.thinking_request_id
                    
                    self.think_thread = threading.Thread(target=self._thinking_process, args=(safe_data, req_id))
                    self.think_thread.start()
                    

        # 3. Low-Level Motion Planning (ì´ë™)
        if self.current_ml_action is None:
            # ìƒê° ì¤‘ì¼ ë•ŒëŠ” ì•ˆì „í•˜ê²Œ ì œìë¦¬ì— ë©ˆì¶°ìˆìŠµë‹ˆë‹¤.
            if self.overcooked_version == '1.1.0':
                return Action.STAY, {}
            return Action.STAY

        # í–‰ë™ ì‹¤í–‰
        self.trace = True 
        chosen_action = Action.STAY
        
        if "wait" in self.current_ml_action:
            self.current_ml_action_steps += 1
            self.time_to_wait -= 1
            if self.time_to_wait <= 0:
                self.current_ml_action = None
            lis_actions = self.mdp.get_valid_actions(state.players[self.agent_index])
            chosen_action = lis_actions[np.random.randint(0,len(lis_actions))]
        else:
            possible_motion_goals = self.find_motion_goals(state)    
            current_motion_goal, chosen_action = self.choose_motion_goal(
                state.players_pos_and_or[self.agent_index], 
                possible_motion_goals, 
                state
            )
            if chosen_action is None:
                 self.current_ml_action = "wait(1)"
                 self.time_to_wait = 1
                 chosen_action = Action.STAY

        self.prev_state = state
        self.current_ml_action_steps += 1

        if self.overcooked_version == '1.1.0':
            return chosen_action, {}
        elif self.overcooked_version == '0.0.1':
            return chosen_action

    def parse_ml_action(self, response, agent_index): 
        if agent_index == 0: 
            pattern = r'layer\s*0: (.+)'
        elif agent_index == 1: 
            pattern = r'layer\s*1: (.+)'
        else:
            raise ValueError("Unsupported agent index.")

        match = re.search(pattern, response)
        action_string = match.group(1).strip() if match else response.strip()

        # 1. Wait ì»¤ë§¨ë“œ ë¨¼ì € ì²˜ë¦¬ (ì‹œê°„ ì¡°ì • ë¡œì§ ë“±ì„ ìœ„í•´)
        if "wait" in action_string:
            def parse_wait_string(s):
                if s == "wait": return 1
                # ìˆ«ìë§Œ ì¶”ì¶œ
                nums = re.findall(r'\d+', s)
                if nums: return int(nums[0])
                return 1
            
            # forced_coordination ë§µì¼ ê²½ìš° ìµœì†Œ 3ì´ˆ ëŒ€ê¸°
            wait_time = parse_wait_string(action_string)
            if self.layout == 'forced_coordination': 
                wait_time = max(3, wait_time)
            
            return f"wait({wait_time})"

        # 2. ì¸ë±ìŠ¤ê°€ í¬í•¨ëœ í•¨ìˆ˜ í˜¸ì¶œí˜• ì•¡ì…˜ (pickup_onion(0)) ì¦‰ì‹œ ë°˜í™˜
        # waitëŠ” ìœ„ì—ì„œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ì œì™¸ë¨
        if re.search(r'\w+\(\d+\)', action_string):
            if "," in action_string:
                action_string = action_string.split(',')[0].strip()
            return action_string

        # 3. ë ˆê±°ì‹œ(êµ¬í˜•) í…ìŠ¤íŠ¸ ì²˜ë¦¬ (LLMì´ ì¸ë±ìŠ¤ ì—†ì´ ë§í–ˆì„ ê²½ìš° ëŒ€ë¹„)
        ml_action = action_string.split()[0] # ê¸°ë³¸ ë‹¨ì–´ ì¶”ì¶œ

        if "place_obj" in action_string: ml_action = "place_obj_on_counter"
        elif "deliver" in action_string: ml_action = "deliver_soup"
        elif "pick" in action_string:
            if "onion" in action_string: ml_action = "pickup_onion" # (0)ì´ ì—†ìœ¼ë©´ ìë™ í• ë‹¹ë¨(find_motion_goalsì—ì„œ)
            elif "tomato" in action_string: ml_action = "pickup_tomato"
            elif "dish" in action_string: ml_action = "pickup_dish"
        elif "put" in action_string:
            if "onion" in action_string: ml_action = "put_onion_in_pot"
            elif "tomato" in action_string: ml_action = "put_tomato_in_pot"
        elif "fill" in action_string:   
            ml_action = "fill_dish_with_soup"
        
        return ml_action

    def generate_ml_action(self, state):
        """
        [Modified] ë‚´ë¶€ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ì—¬ self.last_llm_timingì— ì €ì¥í•©ë‹ˆë‹¤.
        ì´ í•¨ìˆ˜ëŠ” ì´ì œ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.
        """
        # ìƒì„¸ íƒ€ì´ë° ê¸°ë¡ìš© ë”•ì…”ë„ˆë¦¬
        breakdown = {}
        t_start = time.perf_counter()

        # -------------------------------------------------
        # 1. í”„ë¡¬í”„íŠ¸ ìƒì„± (Prompt Construction)
        # -------------------------------------------------
        if self.prompt_level == "l3-aip" and self.belief_revision:
            belief_prompt = self.generate_belief_prompt()
            # print("belief_prompt: ", belief_prompt) # ë¡œê·¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì£¼ì„ ì²˜ë¦¬
        else:
            belief_prompt = ''
        
        state_prompt = belief_prompt + self.generate_state_prompt(state)

        # print(f"\n\n### Observation module to GPT\n")   
        # print(f"{state_prompt}")

        state_message = {"role": "user", "content": state_prompt}
        self.planner.current_user_message = state_message
        
        t_prompt = time.perf_counter()
        breakdown['1_Prompt_Prep'] = t_prompt - t_start

        # -------------------------------------------------
        # 2. LLM ì¶”ë¡  (Inference / API Call)
        # -------------------------------------------------
        # ì‹¤ì œ ì‹œê°„ì´ ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¬ëŠ” êµ¬ê°„
        response = self.planner.query(key=self.openai_api_key(), stop='Scene', trace=self.trace)
        
        t_inference = time.perf_counter()
        breakdown['2_LLM_Inference'] = t_inference - t_prompt

        if 'wait' not in response:
            self.planner.add_msg_to_dialog_history(state_message) 
            self.planner.add_msg_to_dialog_history({"role": "assistant", "content": response})
        
        print(f"\n\n\n### GPT Planner module\n")   
        print("====== GPT Query ======")
        print(response)  
        self.current_thought = response

        if self.prompt_level == "l3-aip":
            generated_intention = self.parse_ml_action(response, 1-self.agent_index)
            self.teammate_intentions_dict[str(self.current_timestep)] = generated_intention
            #print(f"Intention for Player {1 - self.agent_index}: {generated_intention}")

        ml_action = self.parse_ml_action(response, self.agent_index)

        if "wait" not in ml_action:
            self.planner.add_msg_to_dialog_history({"role": "assistant", "content": ml_action})
        
        #print(f"Player {self.agent_index}: {ml_action}")
        self.current_ml_action_steps = 0

        t_parse = time.perf_counter()
        breakdown['3_Parsing'] = t_parse - t_inference
        
        # [NEW] í´ë˜ìŠ¤ ë©¤ë²„ ë³€ìˆ˜ì— ìƒì„¸ ê¸°ë¡ ì €ì¥ (action ë©”ì„œë“œì—ì„œ ì½ê¸° ìœ„í•¨)
        self.last_llm_timing = breakdown
        
        return ml_action

    ##################
    '''
    The followings are the Verificator part
    '''
    ##################

    def check_current_ml_action_done(self, state):
        """
        checks if the current ml action is done
        Supports indexed actions like 'pickup_onion(0)'.
        """
        player = state.players[self.agent_index]
        action = self.current_ml_action
        
        # None ì²´í¬ (ì•ˆì „ì¥ì¹˜)
        if not action:
            return True

        # 1. Pickup ê³„ì—´: í•´ë‹¹ ë¬¼ê±´ì„ ì†ì— ì¥ì—ˆëŠ”ì§€ í™•ì¸
        if "pickup" in action:
            target_obj = None
            if "onion" in action: target_obj = "onion"
            elif "dish" in action: target_obj = "dish"
            elif "tomato" in action: target_obj = "tomato"
            
            # ë¬¼ê±´ì„ ë“¤ê³  ìˆê³ , ê·¸ ë¬¼ê±´ ì´ë¦„ì´ ëª©í‘œì™€ ê°™ìœ¼ë©´ ì™„ë£Œ
            return player.has_object() and player.get_object().name == target_obj
        
        # 2. Fill ê³„ì—´: ë¹ˆ ì ‘ì‹œê°€ ìˆ˜í”„ê°€ ë‹´ê¸´ ì ‘ì‹œë¡œ ë³€í–ˆëŠ”ì§€ í™•ì¸
        elif "fill" in action:
            # ì†ì— ë“  ê²ƒì´ ìˆê³ , ê·¸ ì´ë¦„ì´ 'soup'ì´ë©´ ì™„ë£Œ
            return player.held_object is not None and player.held_object.name == 'soup'
        
        # 3. ì†ì„ ë¹„ìš°ëŠ” í–‰ë™ë“¤ (Put, Place, Deliver)
        # ëƒ„ë¹„ì— ë„£ê±°ë‚˜, ì¹´ìš´í„°ì— ë‘ê±°ë‚˜, ì„œë¹™í•˜ë©´ -> ì†ì´ ë¹”
        elif "put" in action or "place" in action or "deliver" in action:
            return not player.has_object()
        
        # 4. Wait ê³„ì—´: ëŒ€ê¸° ì‹œê°„ì´ ëë‚¬ëŠ”ì§€ í™•ì¸
        elif "wait" in action:
            return self.time_to_wait <= 0
            
        return False

    def validate_current_ml_action(self, state):
        """
        make sure the current_ml_action exists and is valid
        Supports indexed actions (e.g., pickup_onion(0))
        Tomato logic removed.
        """
        if self.current_ml_action is None:
            return False
            
        action = self.current_ml_action
        player = state.players[self.agent_index]
        pot_states_dict = self.mdp.get_pot_states(state)
        
        # í”Œë ˆì´ì–´ ìƒíƒœ í™•ì¸
        has_object = player.has_object()
        has_onion = has_object and player.get_object().name == 'onion'
        has_dish = has_object and player.get_object().name == 'dish'
        has_soup = has_object and player.get_object().name == 'soup'
        
        # ëƒ„ë¹„ ìƒíƒœ ê³„ì‚°
        import pkg_resources
        if self.overcooked_version == '1.1.0':
            soup_ready = len(pot_states_dict['ready']) > 0
            soup_cooking = len(pot_states_dict['cooking']) > 0
            pot_available_for_onion = len(pot_states_dict["empty"] + self.mdp.get_partially_full_pots(pot_states_dict)) > 0
        else:
            # 0.0.1 ë²„ì „
            soup_ready = len(pot_states_dict['onion']['ready']) > 0
            soup_cooking = len(pot_states_dict['onion']['cooking']) > 0
            pot_available_for_onion = len(pot_states_dict["empty"] + pot_states_dict["onion"]['partially_full']) > 0

        # --- ê²€ì¦ ë¡œì§ ---
        
        if "pickup_onion" in action:   
            if len(self.find_motion_goals(state)) == 0: return False
            return not has_object and len(self.mdp.get_onion_dispenser_locations()) > 0

        elif "pickup_dish" in action:
            if len(self.find_motion_goals(state)) == 0: return False
            return not has_object and len(self.mdp.get_dish_dispenser_locations()) > 0
            
        elif "put_onion" in action:
            return has_onion and pot_available_for_onion
            
        elif "place_obj" in action:
            return has_object and len(self.mdp.get_empty_counter_locations(state)) > 0
            
        elif "fill_dish" in action:
            return has_dish and (soup_ready or soup_cooking)
            
        elif "deliver" in action:
            return has_soup
            
        elif "wait" in action:
            return True
            
        return False
   
    def generate_success_feedback(self, state):
        success_feedback = f"### Controller Validation\nPlayer {self.agent_index} succeeded at {self.current_ml_action}. \n"
        print(success_feedback)  
        if 'wait' not in success_feedback:
            self.planner.add_msg_to_dialog_history({"role": "user", "content": f'Player {self.agent_index} succeeded at {self.current_ml_action}.'})
        
    def generate_failure_feedback(self, state):
        failure_feedback = self.generate_state_prompt(state)
        failure_feedback += f" Player {self.agent_index} failed at {self.current_ml_action}."
        failure_feedback += f" Why did Player {self.agent_index} fail ?"     
        print(f"\n~~~~~~~~ Explainer~~~~~~~~\n{failure_feedback}")  
        failure_message = {"role": "user", "content": failure_feedback}
        self.explainer.current_user_message = failure_message
        failure_explanation = self.explainer.query(self.openai_api_key())
        print(failure_explanation)  
        if "wait" not in failure_explanation or self.layout == 'forced_coodination':
            self.explainer.add_msg_to_dialog_history({"role": "user", "content": failure_feedback})
            self.explainer.add_msg_to_dialog_history({"role": "assistant", "content": failure_explanation})
        self.planner.add_msg_to_dialog_history({"role": "user", "content": failure_explanation}) 

    ##################
    '''
    The followings are the Controller part almost inherited from GreedyHumanModel class
    '''
    ##################  
        
    def find_shared_counters(self, state, mlam):  
        counter_dicts = query_counter_states(self.mdp, state) 

        counter_list  = get_intersect_counter(state.players_pos_and_or[self.agent_index],
                        state.players_pos_and_or[1 - self.agent_index], 
                        self.mdp, 
                        self.mlam
                    )    

        #print('counter_list = {}'.format(counter_list))  
        lis = [] 
        for i in counter_list:  
            if counter_dicts[i] == ' ':  
                lis.append(i)       
        available_plans = mlam._get_ml_actions_for_positions(lis)
        return available_plans          

    def find_motion_goals(self, state):
        """
        Generates motion goals based on LLM output strings like 'pickup_onion(0)'.
        Uses self.global_id_mapping to ensure ID consistency.
        """
        am = self.mlam
        motion_goals = []
        player = state.players[self.agent_index]
        
        # -----------------------------------------------------------
        # 1. Helper Function
        # -----------------------------------------------------------
        # -----------------------------------------------------------
        # 1. Helper Function: Calculate interaction spots
        # -----------------------------------------------------------
        def get_interact_states_from_pos(target_pos):
            """Returns valid (pos, orientation) tuples to interact with target_pos."""
            valid_states = []
            x, y = target_pos
            
            # MDPì—ì„œ ë§µ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            width = len(self.mdp.terrain_mtx[0])
            height = len(self.mdp.terrain_mtx)

            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                nx, ny = x + dx, y + dy
                adj_pos = (nx, ny)
                
                # [ìˆ˜ì •] ë§µ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ”ì§€ ë¨¼ì € í™•ì¸í•´ì•¼ í•¨ (IndexError ë°©ì§€)
                if 0 <= nx < width and 0 <= ny < height:
                    # ë²”ìœ„ ì•ˆì¼ ë•Œë§Œ ì§€í˜• íƒ€ì… í™•ì¸
                    if self.mdp.get_terrain_type_at_pos(adj_pos) == ' ':
                        face_dir = (-dx, -dy)
                        valid_states.append((adj_pos, face_dir))
                        
            return valid_states

        # -----------------------------------------------------------
        # 2. Parsing Logic
        # -----------------------------------------------------------
        raw_action = self.current_ml_action.strip()
        target_index = -1
        
        # [ìˆ˜ì •] ë¬¸ìì—´ ìŠ¬ë¼ì´ì‹± ëŒ€ì‹  ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
        # ê´„í˜¸ '('ì™€ ')' ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì°¾ìŠµë‹ˆë‹¤. ì•ë’¤ ê³µë°±ì´ë‚˜ ëì˜ ì (.)ì´ ìˆì–´ë„ ë¬¸ì œì—†ìŠµë‹ˆë‹¤.
        match = self.action_regex.search(raw_action)
        if match:
            # ê³µë°± ì œê±° í›„ ì •ìˆ˜ ë³€í™˜
            target_index = int(match.group(1).strip())

        # -----------------------------------------------------------
        # 3. Handling Indexed Actions (Target Specific Object)
        # -----------------------------------------------------------
        # print("self.global_id_mapping :", self.global_id_mapping)
        # print("target_index :", target_index)
        if target_index != -1:
            target_list_key = None
            
            # ì•¡ì…˜ ì´ë¦„ì— ë”°ë¼ ë§¤í•‘ í‚¤ ì„ íƒ
            if "pickup_onion" in raw_action:
                target_list_key = "onion_dispenser"
            elif "pickup_dish" in raw_action:
                target_list_key = "dish_dispenser"
            elif "pickup_tomato" in raw_action:
                target_list_key = "tomato_dispenser"
            elif "put_onion" in raw_action or "put_tomato" in raw_action or "fill_dish" in raw_action:
                target_list_key = "pot"
            elif "deliver" in raw_action:
                target_list_key = "serving"
            
            # [ìˆ˜ì •ë¨] ì €ì¥í•´ë‘” global_id_mappingì—ì„œ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
            
            if target_list_key:
                targets = self.global_id_mapping.get(target_list_key, [])
                
                if 0 <= target_index < len(targets):
                    target_pos = targets[target_index]
                    motion_goals = get_interact_states_from_pos(target_pos)
                else:
                    print(f"[Warning] Index {target_index} out of bounds for {raw_action}. Avail: {len(targets)}")

        # -----------------------------------------------------------
        # 4. Handling Non-Indexed Actions or Fallbacks
        # -----------------------------------------------------------
        if not motion_goals:
            # ì¸ë±ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë¡œì§(ê°€ê¹Œìš´ ê³³ ì°¾ê¸° ë“±) ìœ ì§€
            if "place_obj_on_counter" in raw_action:
                motion_goals = self.find_shared_counters(state, self.mlam)     
                if len(motion_goals) == 0: 
                    motion_goals = am.place_obj_on_counter_actions(state)
            
            elif "wait" in raw_action:
                motion_goals = am.wait_actions(player)

            # ì¸ë±ìŠ¤ íŒŒì‹± ì‹¤íŒ¨ í˜¹ì€ LLMì´ ì¸ë±ìŠ¤ë¥¼ ì•ˆ ì¤¬ì„ ë•Œì˜ í´ë°±(Fallback)
            elif target_index == -1:
                pot_states_dict = self.mdp.get_pot_states(state)
                counter_objects = self.mdp.get_counter_objects_dict(
                    state, list(self.mdp.terrain_pos_dict["X"])
                )
                
                if "pickup_onion" in raw_action:
                    motion_goals = am.pickup_onion_actions_new(state, counter_objects, state.players_pos_and_or, self.agent_index)
                elif "pickup_dish" in raw_action:
                    motion_goals = am.pickup_dish_actions_new(state, counter_objects, state.players_pos_and_or, self.agent_index)
                elif "put_onion" in raw_action:
                    motion_goals = am.put_onion_in_pot_actions(pot_states_dict)
                elif "fill_dish" in raw_action:
                    motion_goals = am.pickup_soup_with_dish_actions(pot_states_dict, only_nearly_ready=True)
                elif "deliver" in raw_action:
                    motion_goals = am.deliver_soup_actions()
                # í† ë§ˆí†  ë“± ì¶”ê°€ ê°€ëŠ¥
                
        # -----------------------------------------------------------
        # 5. Validation
        # -----------------------------------------------------------
        motion_goals = [
            mg for mg in motion_goals
            if self.mlam.motion_planner.is_valid_motion_start_goal_pair(
                player.pos_and_or, mg
            )
        ]

        return motion_goals
 
    def choose_motion_goal(self, start_pos_and_or, motion_goals, state = None):
        """
        For each motion goal, consider the optimal motion plan that reaches the desired location.
        Based on the plan's cost, the method chooses a motion goal (either boltzmann rationally
        or rationally), and returns the plan and the corresponding first action on that plan.
        """

        if self.controller_mode == 'new':
            (
                chosen_goal,
                chosen_goal_action,
            ) = self.get_lowest_cost_action_and_goal_new(
                start_pos_and_or, motion_goals, state
            )
        else: 
            (
                chosen_goal,
                chosen_goal_action,
            ) = self.get_lowest_cost_action_and_goal(
                start_pos_and_or, motion_goals
            )
        return chosen_goal, chosen_goal_action
    
    def get_lowest_cost_action_and_goal(self, start_pos_and_or, motion_goals):
        """
        Chooses motion goal that has the lowest cost action plan.
        Returns the motion goal itself and the first action on the plan.
        """
        min_cost = np.Inf
        best_action, best_goal = None, None
        for goal in motion_goals:
            action_plan, _, plan_cost = self.mlam.motion_planner.get_plan(
                start_pos_and_or, goal
            )
            if plan_cost < min_cost:
                best_action = action_plan[0]
                min_cost = plan_cost
                best_goal = goal
        return best_goal, best_action
 
    def get_lowest_cost_action_and_goal_new(self, start_pos_and_or, motion_goals, state): 
        """
        Chooses motion goal that has the lowest cost action plan.
        Returns the motion goal itself and the first action on the plan.
        """   
        min_cost = np.Inf
        best_action, best_goal = None, None
        for goal in motion_goals:   
            action_plan, plan_cost = self.real_time_planner(
                start_pos_and_or, goal, state
            )     
            if plan_cost < min_cost:
                best_action = action_plan
                min_cost = plan_cost
                best_goal = goal     
        if best_action is None: 
            # print('\n\n\nBlocking Happend, executing default path\n\n\n')
            # print('current position = {}'.format(start_pos_and_or)) 
            # print('goal position = {}'.format(motion_goals))        
            # if np.random.rand() < 0.5:  
            #     return None, Action.STAY
            # else: 
            return self.get_lowest_cost_action_and_goal(start_pos_and_or, motion_goals)
        return best_goal, best_action

    def real_time_planner(self, start_pos_and_or, goal, state):   
        other_pos_and_or = state.players_pos_and_or[1 - self.agent_index]
        # ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” self.cached_terrain_matrix ì‚¬ìš©
        action_plan, plan_cost = find_path(start_pos_and_or, other_pos_and_or, goal, self.cached_terrain_matrix) 
        return action_plan, plan_cost
    
class ProPlanningAgent(ProAgent):
    def __init__(self, model="Qwen/Qwen2-VL-7B-Instruct-AWQ"):
        super().__init__(model=model)


# def generate_state_prompt(self, state):
#     ego = state.players[self.agent_index]
#     teammate = state.players[1 - self.agent_index]

#     time_prompt = f"Scene {state.timestep}: "
#     ego_object = ego.held_object.name if ego.held_object else "nothing"
#     teammate_object = teammate.held_object.name if teammate.held_object else "nothing"
#     ego_state_prompt = f"<Player {self.agent_index}> holds "
#     if ego_object == 'soup':
#         ego_state_prompt += f"a dish with {ego_object} and needs to deliver soup.  "
#     elif ego_object == 'nothing':
#         ego_state_prompt += f"{ego_object}. "
#     else:
#         ego_state_prompt += f"one {ego_object}. "
    
#     teammate_state_prompt = f"<Player {1-self.agent_index}> holds "
#     if teammate_object == 'soup':
#         teammate_state_prompt += f"a dish with {teammate_object}. "
#     elif teammate_object == "nothing":
#         teammate_state_prompt += f"{teammate_object}. "
#     else:
#         teammate_state_prompt += f"one {teammate_object}. "

    
#     kitchen_state_prompt = "Kitchen states: "
#     prompt_dict = {
#         "empty": "<Pot {id}> is empty; ",
#         "cooking": "<Pot {id}> starts cooking, the soup will be ready after {t} timesteps; ",
#         "ready": "<Pot {id}> has already cooked the soup; ",
#         "1_items": "<Pot {id}> has 1 onion; ",
#         "2_items": "<Pot {id}> has 2 onions; ",
#         "3_items": "<Pot {id}> has 3 onions and is full; "
#     }

#     pot_states_dict = self.mdp.get_pot_states(state)   

#     if pkg_resources.get_distribution("overcooked_ai").version == '1.1.0':
#         for key in pot_states_dict.keys():
#             if key == "cooking":
#                 for pos in pot_states_dict[key]:
#                     pot_id = self.pot_id_to_pos.index(pos)
#                     soup_object = state.get_object(pos)
#                     kitchen_state_prompt += prompt_dict[key].format(id=pot_id, t=soup_object.cook_time_remaining)
#             else:
#                 for pos in pot_states_dict[key]:
#                     pot_id = self.pot_id_to_pos.index(pos)
#                     kitchen_state_prompt += prompt_dict[key].format(id=pot_id) 
    
#     elif pkg_resources.get_distribution("overcooked_ai").version == '0.0.1':
#         for key in pot_states_dict.keys():
#             if key == "empty":
#                 for pos in pot_states_dict[key]: 
#                     pot_id = self.pot_id_to_pos.index(pos)
#                     kitchen_state_prompt += prompt_dict[key].format(id=pot_id)     
#             else: # key = 'onion' or 'tomota'
#                 for soup_key in pot_states_dict[key].keys():
#                     # soup_key: ready, cooking, partially_full
#                     for pos in pot_states_dict[key][soup_key]:
#                         pot_id = self.pot_id_to_pos.index(pos)
#                         soup_object = state.get_object(pos)
#                         soup_type, num_items, cook_time = soup_object.state
#                         if soup_key == "cooking":
#                             kitchen_state_prompt += prompt_dict[soup_key].format(id=pot_id, t=self.mdp.soup_cooking_time-cook_time)
#                         elif soup_key == "partially_full":
#                             pass
#                         else:
#                             kitchen_state_prompt += prompt_dict[soup_key].format(id=pot_id)


#     intersect_counters = get_intersect_counter(
#                             state.players_pos_and_or[self.agent_index], 
#                             state.players_pos_and_or[1 - self.agent_index], 
#                             self.mdp, 
#                             self.mlam
#                         )
#     counter_states = query_counter_states(self.mdp, state)  

#     if self.layout == 'forced_coordination': 
#         kitchen_state_prompt += '{} counters can be visited by <Player {}>. Their states are as follows: '.format(len(intersect_counters), self.agent_index)
#         count_states = {}  
#         for i in intersect_counters:  
#             obj_i = 'nothing' 
#             if counter_states[i] != ' ': 
#                 obj_i = counter_states[i]                
#             if obj_i in count_states:  
#                 count_states[obj_i] += 1
#             else: 
#                 count_states[obj_i]  = 1 
#         total_obj = ['onion', 'dish']
#         for i in count_states:   
#             if i == 'nothing': 
#                 continue 
#             kitchen_state_prompt += f'{count_states[i]} counters have {i}. '   
#         for i in total_obj: 
#             if i not in count_states:        
#                 kitchen_state_prompt += f'No counters have {i}. ' 

#     if self.layout == 'forced_coordination': 
#         teammate_state_prompt = ""
#     print("PROMPT:",self.layout_prompt + time_prompt + ego_state_prompt +
#             teammate_state_prompt + kitchen_state_prompt)
#     return (self.layout_prompt + time_prompt + ego_state_prompt +
#             teammate_state_prompt + kitchen_state_prompt)